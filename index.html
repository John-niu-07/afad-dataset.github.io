<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>AFAD-Dataset.GitHub.io by afad-dataset</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">The Asian Face Age Dataset (AFAD) -- Available for download</h1>
      <h2 class="project-tagline">AFAD-Dataset.GitHub.io</h2>
    </section>

    <section class="main-content">
      <h1>
<a id="the-afad-dataset" class="anchor" href="#the-afad-dataset" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The AFAD Dataset</h1>

<p>Authors: Zhenxing Niu, Mo Zhou, Xinbo Gao, Gang Hua</p>

<hr>

<p><img src="https://raw.githubusercontent.com/afad-dataset/pictures/master/afad.png" alt="afad">  </p>

<h2>
<a id="brief-introduction" class="anchor" href="#brief-introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Brief Introduction</h2>

<p>The Asian Face Age Dataset (AFAD) is a new dataset proposed for evaluating the performance of age estimation, which contains more than 160K facial images and the corresponding age and gender labels. This dataset is oriented to age estimation on Asian faces, so all the facial images are for Asian faces. 
It is noted that the AFAD is the biggest dataset for age estimation to date. It is well suited to evaluate how deep learning methods can be adopted for age estimation. </p>

<h2>
<a id="motivation" class="anchor" href="#motivation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Motivation</h2>

<p>For age estimation, there are several public datasets for evaluating the performance of a specific algorithm, such as FG-NET [1] (1002 face images), MORPH I (1690 face images), and MORPH II[2] (55,608 face images). Among them, the MORPH II is the biggest public dataset to date. On the other hand, as we know it is necessary to collect a large scale dataset to train a deep Convolutional Neural Network. Therefore, the MORPH II dataset is extensively used to evaluate how deep learning methods can be adopted for age estimation [3][4].</p>

<p>However, the ethnic is very unbalanced for the MORPH II dataset, i.e., it has only less than 1% Asian faces. In order to evaluate the previous methods for age estimation on Asian Faces, the Asian Face Age Dataset (AFAD) was proposed. </p>

<h2>
<a id="statistics-and-some-samples" class="anchor" href="#statistics-and-some-samples" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Statistics and some samples</h2>

<p><img src="https://raw.githubusercontent.com/afad-dataset/pictures/master/stat.png" alt="stat">  </p>

<p>There are 164,432 well-labeled photos in the AFAD dataset. It consist of 63,680 photos for female as well as 100,752 photos for male, and the ages range from 15 to 40. The distribution of photo counts for distinct ages are illustrated in the figure above. Some samples are shown in the Figure on the top. Its download link is provided in the "Download" section. </p>

<p>In addition, we also provide a subset of the AFAD dataset, called AFAD-Lite, which only contains PLACEHOLDER well-labeled photos. It consist of PLACEHOLDER photos for female as well as PLACEHOLDER photos for male, and the ages range from 15 to 40. The distribution of photo counts for distinct ages are illustrated in Fig. PLACEHOLDER. Its download link is also provided in the "Download" section. </p>

<h2>
<a id="detailed-information-for-the-afad-dataset" class="anchor" href="#detailed-information-for-the-afad-dataset" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Detailed information for the AFAD dataset</h2>

<p>The AFAD dataset is built by collecting selfie photos on a particular social network -- RenRen Social Network (RSN) [5]. The RSN is widely used by Asian students including middle school, high school, undergraduate, and graduate students. Even after leaving from school, some people still access their RSN account to connect with their old classmates. So, the age of the RSN user crosses a wide range from 15-years to more than 40-years old. </p>

<h2>
<a id="publications" class="anchor" href="#publications" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Publications</h2>

<p>Zhenxing Niu, Mo Zhou, Xinbo Gao, Gang Hua. Ordinal Regression with a Multiple Output CNN for Age Estimation. CVPR, 2016</p>

<h2>
<a id="download" class="anchor" href="#download" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Download</h2>

<p>Please notice that this dataset is made available for academic research purpose only.</p>

<h4>
<a id="1-dataset-afad-lite" class="anchor" href="#1-dataset-afad-lite" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1 Dataset: AFAD-LITE</h4>

<p>AFAD-LITE is a subset of the complete AFAD dataset, which contains images of 22
continuous ages, in the amount of 60K.</p>

<p> https://github.com/afad-dataset/tarball-lite </p>

<h4>
<a id="2-dataset-afad" class="anchor" href="#2-dataset-afad" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2 Dataset: AFAD</h4>

<p>AFAD is the complete version of AFAD dataset.</p>

<p> https://github.com/afad-dataset/tarball </p>

<h2>
<a id="experiment-results" class="anchor" href="#experiment-results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Experiment Results</h2>

<table>
<thead>
<tr>
<th>Method</th>
<th>MAE on MORPH II</th>
<th>MAE on AFAD</th>
</tr>
</thead>
<tbody>
<tr>
<td>BIFS+LSVR [6]</td>
<td>4.31</td>
<td>4.13</td>
</tr>
<tr>
<td>BIFS+CCA [7]</td>
<td>4.73</td>
<td>4.40</td>
</tr>
<tr>
<td>CNN+LSVR [8]</td>
<td>5.13</td>
<td>5.56</td>
</tr>
<tr>
<td>BIFS+OR-SVM [9]</td>
<td>4.21</td>
<td>4.36</td>
</tr>
<tr>
<td>BIFS+OHRank [10]</td>
<td>3.82</td>
<td>3.84</td>
</tr>
<tr>
<td>OURS []</td>
<td>3.27</td>
<td>3.34</td>
</tr>
</tbody>
</table>

<h2>
<a id="code" class="anchor" href="#code" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Code</h2>

<p>To Be Updated.</p>

<h2>
<a id="faq" class="anchor" href="#faq" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>FAQ</h2>

<p>To Be Updated.</p>

<h2>
<a id="reference" class="anchor" href="#reference" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Reference</h2>

<ul>
<li>[1] The fg-net aging database. <a href="http://sting.cycollege.ac.cy/alanitis/fgnetaging.html">http://sting.cycollege.ac.cy/alanitis/fgnetaging.html</a>.</li>
<li>[2] K. Ricanek and T. Tesafaye. Morph: A longitudinal image database of normal adult age-progression. IEEE International Conference on Automatic Face and Gesture Recognition, pages 341–345, 2015.</li>
<li>[3] D. Yi, Z. Lei, and S. Li. Age estimation by multi-scale convolutional network. ACCV, pages 144–158, 2014.</li>
<li>[4] X. Wang, R. Guo, and C. Kambhamettu. Deeply-learned feature for age estimation. WACV, pages 534–541, 2015.</li>
<li>[5] Renren social network. <a href="http://www.renren.com/">http://www.renren.com/</a>.</li>
<li>[6] G. Guo, G. Mu, Y. Fu, and T. Huang. Human age estimation using bio-inspired features. CVPR, pages 112–119, 2009.</li>
<li>[7] G. Guo and G. Mu. Joint estimation of age, gender and ethnicity: Cca vs. pls. FG, pages 1–6, 2013.</li>
<li>[8] X. Wang, R. Guo, and C. Kambhamettu. Deeply-learned feature for age estimation. WACV, pages 534–541, 2015.</li>
<li>[9] K. Chang, C. Chen, and Y. Hung. A ranking approach for human age estimation based on face images. ICPR, 2010.</li>
<li>[10] K. Chang, C. Chen, and Y. Hung. Ordinal hyperplanes ranker with cost sensitivities for age estimation. CVPR, pages 585–592, 2011.</li>
</ul>

      <footer class="site-footer">

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
