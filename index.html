<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>AFAD-Dataset.GitHub.io by afad-dataset</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">AFAD-Dataset.GitHub.io</h1>
      <h2 class="project-tagline">The Asian Face Age Dataset (AFAD)</h2>
    </section>

    <section class="main-content">
      <h1>
<a id="the-afad-dataset" class="anchor" href="#the-afad-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>The AFAD Dataset</h1>

<p>Authors: Anonymous</p>

<hr>

<p><img src="https://raw.githubusercontent.com/afad-dataset/pictures/master/afad1.png" alt="afad1"><br>
<img src="https://raw.githubusercontent.com/afad-dataset/pictures/master/afad2.png" alt="afad2"><br>
<img src="https://raw.githubusercontent.com/afad-dataset/pictures/master/afad3.png" alt="afad3">  </p>

<h2>
<a id="brief-introduction" class="anchor" href="#brief-introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Brief Introduction</h2>

<p>The Asian Face Age Dataset (AFAD) is a new dataset proposed for evaluating the performance of age estimation, which contains more than 160K facial images and the corresponding age and gender labels. This dataset is oriented to age estimation on Asian faces, so all the facial images are for Asian faces. 
It is noted that the AFAD is the biggest dataset for age estimation to date. It is well suited to evaluate how deep learning methods can be adopted for age estimation. </p>

<h2>
<a id="motivation" class="anchor" href="#motivation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Motivation</h2>

<p>For age estimation, there are several public datasets for evaluating the performance of a specific algorithm, such as FG-NET [1] (1002 face images), MORPH I (1690 face images), and MORPH II[2] (55,608 face images). Among them, the MORPH II is the biggest public dataset to date. On the other hand, as we know it is necessary to collect a large scale dataset to train a deep Convolutional Neural Network. Therefore, the MORPH II dataset is extensively used to evaluate how deep learning methods can be adopted for age estimation [3][4].</p>

<p>However, the ethnic is very unbalanced for the MORPH II dataset, i.e., it has only less than 1% Asian faces. In order to evaluate the previous methods for age estimation on Asian Faces, the Asian Face Age Dataset (AFAD) was proposed. </p>

<h2>
<a id="statistics-and-some-samples" class="anchor" href="#statistics-and-some-samples" aria-hidden="true"><span class="octicon octicon-link"></span></a>Statistics and some samples</h2>

<p>There are 164,432 well-labeled photos in the AFAD dataset. It consist of 63,680 photos for female as well as 100,752 photos for male, and the ages range from 15 to 40. The distribution of photo counts for distinct ages are illustrated in Fig. PLACEHOLDER. Some samples are shown in the Figure on the top. It can be download here. </p>

<p>In addition, we also provide a subset of the AFAD dataset, called AFAD-Lite, which only contains PLACEHOLDER well-labeled photos. It consist of PLACEHOLDER photos for female as well as PLACEHOLDER photos for male, and the ages range from 15 to 40. The distribution of photo counts for distinct ages are illustrated in Fig. PLACEHOLDER. It can be download here. </p>

<h2>
<a id="detailed-information-for-the-afad-dataset" class="anchor" href="#detailed-information-for-the-afad-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Detailed information for the AFAD dataset</h2>

<p>The AFAD dataset is built by collecting selfie photos on a particular social network -- RenRen Social Network (RSN) [5]. The RSN is widely used by Asian students including middle school, high school, undergraduate, and graduate students. Even after leaving from school, some people still access their RSN account to connect with their old classmates. So, the age of the RSN user crosses a wide range from 15-years to more than 40-years old. </p>

<h2>
<a id="publications" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h2>

<p>Unpublished</p>

<h2>
<a id="download" class="anchor" href="#download" aria-hidden="true"><span class="octicon octicon-link"></span></a>Download</h2>

<p>Please notice that this dataset is made available for academic research purpose only.</p>

<h4>
<a id="1-dataset-afad-lite" class="anchor" href="#1-dataset-afad-lite" aria-hidden="true"><span class="octicon octicon-link"></span></a>1 Dataset: AFAD-LITE</h4>

<p>AFAD-LITE is a subset of the complete AFAD dataset, which contains images of 22
continuous ages, in the amount of 60K.</p>

<p>The resource is under preparation..  </p>

<h4>
<a id="2-dataset-afad" class="anchor" href="#2-dataset-afad" aria-hidden="true"><span class="octicon octicon-link"></span></a>2 Dataset: AFAD</h4>

<p>AFAD is the complete version of AFAD dataset.</p>

<p>The resource is under preparation.  </p>

<h2>
<a id="experiment-results" class="anchor" href="#experiment-results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment Results</h2>

<table>
<thead>
<tr>
<th>Method</th>
<th>MAE on MORPH II</th>
<th>MAE on AFAD</th>
</tr>
</thead>
<tbody>
<tr>
<td>BIFS+LSVR</td>
<td>4.31</td>
<td>4.13</td>
</tr>
<tr>
<td>BIFS+CCA</td>
<td>4.73</td>
<td>4.40</td>
</tr>
<tr>
<td>CNN+LSVR</td>
<td>5.13</td>
<td>5.56</td>
</tr>
<tr>
<td>BIFS+OR-SVM</td>
<td>4.21</td>
<td>4.36</td>
</tr>
<tr>
<td>BIFS+OHRank</td>
<td>3.82</td>
<td>3.84</td>
</tr>
<tr>
<td>OURS</td>
<td>pending</td>
<td>pending</td>
</tr>
</tbody>
</table>

<h2>
<a id="code" class="anchor" href="#code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code</h2>

<p>To Be Updated.</p>

<h2>
<a id="faq" class="anchor" href="#faq" aria-hidden="true"><span class="octicon octicon-link"></span></a>FAQ</h2>

<p>To Be Updated.</p>

<h2>
<a id="reference" class="anchor" href="#reference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reference</h2>

<ul>
<li>[1] The fg-net aging database. <a href="http://sting.cycollege.ac.cy/alanitis/fgnetaging.html">http://sting.cycollege.ac.cy/alanitis/fgnetaging.html</a>.</li>
<li>[2] K. Ricanek and T. Tesafaye. Morph: A longitudinal image database of normal adult age-progression. IEEE International Conference on Automatic Face and Gesture Recognition, pages 341–345, 2015.</li>
<li>[3] D. Yi, Z. Lei, and S. Li. Age estimation by multi-scale convolutional network. ACCV, pages 144–158, 2014.</li>
<li>[4] X. Wang, R. Guo, and C. Kambhamettu. Deeply-learned feature for age estimation. WACV, pages 534–541, 2015.</li>
<li>[5] Renren social network. <a href="http://www.renren.com/">http://www.renren.com/</a>.</li>
</ul>

      <footer class="site-footer">

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
